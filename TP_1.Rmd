Primero se cargan todas las librerias que se van a estar usando en el trabajo

```{r}
rm(list=ls())

library(lubridate)
library(ggplot2)
library(dplyr)
library('rmarkdown')
library(pwr)
library(boot)
library(plotly)
```
```{r}
options(scipen=999) #para evitar trabajar con notaci贸n cient铆fica
```

A continuacion se cargan los datos:

  - La base de recorridos de bicicletas durante el 2018
  - Los archivos de id_usuarios para los a帽os 2015,2016,2017,2018

```{r}

setwd('C:/Users/elosasso/OneDrive - Universidad Torcuato Di Tella/Metodos estadisticos aplicados a negocios/TP1/MEAN_TP1')

df <- read.csv('recorridos-realizados-2018.csv')

users_2018 <- read.csv('usuarios-ecobici-2018.csv')
users_2017 <- read.csv('usuarios-ecobici-2017.csv')
users_2016 <- read.csv('usuarios-ecobici-2016.csv')
users_2015 <- read.csv('usuarios-ecobici-2015.csv')

users <- rbind(users_2018,users_2017,users_2016,users_2015)
```

```{r}

str(df)

```

Se ven algunas variables que se declararon mal el tipo: fecha_origen_recorrido, duracion_recorrido y fecha_destino_recorrido. Se cambian a sus tipos correspondientes

```{r}
df$fecha_origen_recorrido <- as.POSIXct(strptime(df$fecha_origen_recorrido, format = "%Y-%m-%d %H:%M:%OS",
                                      tz = "America/Argentina/Buenos_Aires"))

df$duracion_recorrido <- as.numeric(df$duracion_recorrido, units = 'secs') #Hay que verificar si estan bien calculadas!

df$fecha_destino_recorrido <- as.POSIXct(strptime(df$fecha_destino_recorrido, format = "%Y-%m-%d %H:%M:%OS",
                                      tz = "America/Argentina/Buenos_Aires"))
```
Siempre es de mucho provecho contar con datos de tipo fecha. Por eso se generan nuevas variables para obtener el d铆a, mes y la hora de la semana en la que se extrajeron las bicicletas.

```{r}
df$dia_de_semana_origen   <- wday(df$fecha_origen_recorrido, label = TRUE,
                              abbr = FALSE)
df$hora_del_dia_origen <- hour(df$fecha_origen_recorrido)

df$mes_de_origen <- month(df$fecha_origen_recorrido, label = TRUE,
                          abbr = FALSE)

```

```{r}
head(select(df,dia_de_semana_origen,hora_del_dia_origen,mes_de_origen))
```

Punto 1: An谩lisis exploratorio
------------------------------

Se analizan algunos gr谩ficos para entender la distribuci贸n de algunas m茅tricas como la edad, el uso de las bicicletas, frecuencia, lugares, etc. 

```{r}
boxplot(df$duracion_recorrido, xlab = 'Duracion del recorrido (seg)', main = 'Distribucion del tiempo de uso', horizontal = TRUE)
abline(v = median(df$duracion_recorrido), col = 'red', lty = 2)
```

Vemos que si bien existen outliers, lo normal es que una persona use una bicicleta hasta unos 3000/4000 segundos (~50 minutos/ 1 hora). Lo que tiene sentido porque es el tiempo permitido para cada recorrido.
La explicaci贸n para tiempos mayores puede deberse a que durante los fines de semana se permit铆a un uso de hasta 2 horas por recorrido.


Para entender si visualmente existe un horario en el que m谩s se usen las bicicletas, se grafica la cantidad de extracciones por hora, para cada d铆a de la semana.

```{r}
ggplot(data = df) + geom_bar(mapping = aes(x = hora_del_dia_origen)) + facet_wrap(~ dia_de_semana_origen) + labs(x = 'Hora del d铆a') + ggtitle('Cantidad de extracciones por hora del d铆a, seg煤n el d铆a de la semana')
```

Se observa que en todos los d铆as existe un cierto 'patron' bastante com煤n. Los horarios picos son entre las 15:00 y las 20:00 horas, a partir de la cual baja el uso. Se observa un leve repunte en las primeras horas del d铆a, pero en general, entre la 1:00 y las 5:00 am son los horarios m谩s tranquilos. 

Si bien tienen (aparentemente) el mismo comportamiento que durante los d铆as de semana, vemos que durante los fines de semana cae el uso.

Aprovechando que tenemos datos de fecha, observamos la cantidad de extracciones por mes.

```{r}
ggplot(data = df) + geom_bar(mapping = aes(y = mes_de_origen)) + labs(x = 'Cantidad de extracciones', y = 'Mes') + ggtitle('Cantidad de extracciones por mes')
```


Pareciera haber un mayor n煤mero de extracciones en los meses de agosto, septiembre y octubre, con un menor uso durante enero, febrero y marzo (podr铆a explicarse por las vacaciones?)

Otro dato interesante de obtener es la cantidad de extracciones por estaci贸n, para ver si hay alguna zona en particular con mayor movimiento, para eso creamos una tabla con las estaciones y sus ubicaciones, junto  con la cantidad de extracciones en cada una.


```{r}
mapa <- df %>% filter(complete.cases(lat_estacion_origen)) %>% group_by(nombre_estacion_origen, lat_estacion_origen, long_estacion_origen) %>% summarize(q = n()) %>% ungroup()
mapa
```

Visualizamos en un mapa:

```{r}

library(leaflet)

pal <- colorNumeric(c('blue','yellow','red'), domain = mapa$q)

m <- leaflet(data = mapa) %>% 
   addProviderTiles(providers$CartoDB.Positron) %>%
  addCircleMarkers(lng=mapa$long_estacion_origen, lat=mapa$lat_estacion_origen,
                   radius = 3,
                   col = ~pal(q),
                   stroke = FALSE,
                   fillOpacity = 0.8) %>%
  addLegend(pal = pal, values = ~q)
m  # Print the map

```

Se ve que pocas estaciones superan las 25 mil extracciones, pero si puede verse que en las zonas de once, almagro, villa cresto, palermo, existe un n煤mero mayor de extracciones.

Al mismo tiempo, las zonas de puerto madero y el sur de la capital poseen un menor n煤mero de extracciones.

**NOTA: Notar que no est谩n todas las estaciones que uno esperar铆a, esto fue porque muchos registros ten铆an NAs en sus valores de latitud y longitud, por lo que no pudieron ubicarse.**

Para poder analizar los casos de los recorridos entre las estaciones Parque las heras y Billingurst primero verificamos qu茅 tan com煤n es el recorrido.

```{r}

df$misma_estacion <- df$nombre_estacion_origen == df$nombre_estacion_destino

bicis = as.data.frame(df)

bicis %>% filter((!is.na(id_estacion_origen)) & (!is.na(id_estacion_destino)) & (misma_estacion == FALSE)) %>% 
  group_by(nombre_estacion_origen,nombre_estacion_destino) %>%  
  summarize(count = n()) %>% arrange(desc(count)) %>% ungroup()

bicis %>% filter((id_estacion_origen == 009) & (id_estacion_destino == 066)) %>% select(nombre_estacion_origen,nombre_estacion_destino) %>% 
  group_by(nombre_estacion_origen,nombre_estacion_destino) %>% summarize(count = n()) %>% ungroup()

```

Vemos entonces que se hicieron 1091 viajes entre ambas estaciones, no es el viaje m谩s hecho, pero si es uno bastante frecuente.

Apartado: Descubrimiento sobre el tiempo del recorrido
------------------------------------------------------

Dado que el punto solicita hacer un test de hip贸tesis sobre la duraci贸n del recorrido, buscamos comprobar que tan confiables eran los datos de 'duracion de recorrido' provisto por los datos.

```{r}

df$duracion_recorrido_manual <- as.numeric((df$fecha_destino_recorrido - df$fecha_origen_recorrido), units = 'secs')

ggplot(filter(df,(id_estacion_origen == 009) & (id_estacion_destino == 066))) + 
         geom_density(aes(x = duracion_recorrido_manual),fill = 'red', alpha = 0.3) +
         geom_density(aes(x = duracion_recorrido),fill = 'green', alpha = 0.3) +
         ggtitle('Distribucion de la duracion de los recorridos') + labs(x = 'Duracion de recorrido')
```

El grafico pareciera sugerir que ambas variables tienen medias distintas, por lo cual sospechamos que los datos provistos por el gobierno no est谩n del todo acertados. Para confirmar las sospechas, realizamos un test de hip贸tesis.

```{r}

temp <- filter(df,(id_estacion_origen == 009) & (id_estacion_destino == 066) & (complete.cases(duracion_recorrido_manual)))

t.test(temp$duracion_recorrido,temp$duracion_recorrido_manual, paired = TRUE, alternative = 'two.sided')
```

Evidentemente, **ambas medidas no son iguales**. Puntualmente, la variable *'duracion_recorrido'* provista por el gobierno, difiere de la duracion calculada manualmente en 298 segundos (~ 5 minutos) por *debajo*.

En base a esta informaci贸n, se va a realizar el test de hip贸tesis sober la variable 'duracion_recorrido_manual', porque se entiende que es m谩s confiable y qued贸 demostrado que es significativamente diferente del valor originalmente provisto.

Levantando las altas del 2018 y los recorridos del 2018:
```{r}
altas <- read.csv("usuarios-ecobici-2018.csv",
                  header = TRUE, sep = ",")

summary(altas)
dim(altas)
prop.table(table(altas$usuario_sexo))

recorridos <- read.csv("recorridos-realizados-2018.csv",
                       header = TRUE, sep = ",")

#Creo una columna que indique el dia de la semana en el que se retiro la bici.
recorridos$dia_semana <- as.factor(strftime(recorridos$fecha_origen_recorrido, "%A"))

summary(recorridos)
dim(recorridos)
prop.table(table(recorridos$genero_usuario))
prop.table(table(recorridos$dia_semana))
```
Respecto a las altas:
Vemos que en el 2018 se dieron de alta 56182 usuarios, de los cuales aproximadamente el 46% es femenino y el 54% masculino. El dia donde mas altas se dieron fue el 08/10/2018. La hora en la cual ms usuarios se dan de alta es a las 5:57:45. La edad promedio de los usuarios es de 33 aos.

Respecto a los recorridos:
Vemos que en el 2018 se hicieron 2619968 recorridos, que tanto el origen como el destino ms comun se da en la Facultad de Medicina y que las mujeres hicieron aproximadamente el 28% de los recorridos, mientras que los hombres el 72%. El da de la semana en el que mas bicis son retiradas es el miercoles.


Punto dos
---------
```{r}
recorridos$fecha_origen_auxiliar <- as.factor(strptime(recorridos$fecha_origen_recorrido,
                                                       format = "%Y-%m-%d",
                                                       tz = "America/Argentina/Buenos_Aires"))
library("dplyr")
usuarios_diarios_ao <- recorridos %>% group_by(fecha_origen_auxiliar) %>% summarise(total = length(dia_semana)) %>% ungroup()
usuarios_diarios_ao$total <- as.numeric(usuarios_diarios_ao$total)
usuarios_diarios_ao$dia_semana <- as.factor(strftime(usuarios_diarios_ao$fecha_origen_auxiliar, "%A"))
tab <- usuarios_diarios_ao %>% group_by(dia_semana) %>% summarise(mu = mean(total)) %>% ungroup()
tab$z <- usuarios_diarios_ao %>% group_by(dia_semana) %>% summarise(mu = qt(0.975, length(total) - 1)) %>% ungroup()
tab$std <- usuarios_diarios_ao %>% group_by(dia_semana) %>% summarise(mu = sd(total)/sqrt(length(total))) %>% ungroup()
tab$lim_inf <- tab$mu - (tab$z$mu*tab$std$mu)
tab$lim_sup <- tab$mu + (tab$z$mu*tab$std$mu)

library("ggplot2")
tab$dia_semana <- factor(tab$dia_semana, levels = c("lunes","martes","mircoles","jueves","viernes","sbado","domingo"))
grafIC <- ggplot(data = tab) + geom_pointrange(mapping = aes(x = dia_semana, y = mu, ymin = lim_inf, ymax = lim_sup)) + geom_errorbar(mapping = aes(x = dia_semana, ymin = lim_inf, ymax = lim_sup))

grafIC
```
En el grfico que muestra los intervalos de confianza de la cantidad media de usuarios por cada dia de la semana encontramos evidencia estadistica de una estacionalidad en el uso de las bicis los dias de semana (lunes a viernes), donde vemos que los IC se solapan y son superiores a los de los dias de fin de semana (sabado y domingo).


Punto tres
----------
```{r}
feriados <- c("2018-01-01", "2018-02-12", "2018-02-13", "2018-03-24", "2018-03-29", "2018-03-30",
              "2018-04-02", "2018-04-30", "2018-05-01", "2018-05-25", "2018-06-17", "2018-06-20",
              "2018-07-09", "2018-08-20", "2018-09-15", "2018-10-19", "2018-12-08", "2018-12-24",
              "2018-12-25", "2018-12-31")
usuarios_diarios_ao$es_feriado <- factor(ifelse(usuarios_diarios_ao$fecha_origen_auxiliar %in% feriados,
                                                 1, 0))

tab <- usuarios_diarios_ao %>% filter(es_feriado == 0) %>% group_by(dia_semana) %>% summarise(mu = mean(total)) %>% ungroup()
tab$z <- usuarios_diarios_ao %>% filter(es_feriado == 0) %>% group_by(dia_semana) %>% summarise(mu = qt(0.975, length(total) - 1)) %>% ungroup()
tab$std <- usuarios_diarios_ao %>% filter(es_feriado == 0) %>% group_by(dia_semana) %>% summarise(mu = sd(total)/sqrt(length(total))) %>% ungroup()
tab$lim_inf <- tab$mu - (tab$z$mu*tab$std$mu)
tab$lim_sup <- tab$mu + (tab$z$mu*tab$std$mu)

tab$dia_semana <- factor(tab$dia_semana, levels = c("lunes","martes","mircoles","jueves","viernes","sbado","domingo"))
grafIC_sin_feriados <- ggplot(data = tab) + geom_pointrange(mapping = aes(x = dia_semana, y = mu, ymin = lim_inf, ymax = lim_sup)) + geom_errorbar(mapping = aes(x = dia_semana, ymin = lim_inf, ymax = lim_sup))

grafIC_sin_feriados
```
Si descontamos del analisis los dias que fueron feriados vemos que la media de uso diario de bicis aumenta en general pero se mantiene la estacionalidad los dias de semana (lunes a viernes).


Punto 4
-------

Para encarar este problema primero se realizo un extracto de los datos con informaci贸n de todos los viajes realizados por este usuario, con la finalidad de obtener los kil贸metros entre cada una de las estaciones.

```{r, cache=TRUE}
posUsuario<- recorridos$id_usuario == 606320
recorridosCiclista<- recorridos[posUsuario,] %>%
    group_by(id_estacion_origen,lat_estacion_origen,long_estacion_origen,
             id_estacion_destino,lat_estacion_destino,long_estacion_destino) %>%
    summarise(recorridos = length(id_estacion_origen))
recorridosCiclista<- as.data.frame(recorridosCiclista)
recorridosCiclista<- recorridosCiclista[complete.cases(recorridosCiclista),]
kable(head(recorridosCiclista))
```

Luego se busco la distancia entre cada uno de los puntos en [Google Maps](https://www.google.com.ar/maps), y se agrego esta informaci贸n al datadrame, y finalmente se calculo la media arm贸nica y la media aritm茅tica de la velocidad para este usuario.

```{r, cache=TRUE}
recorridosCiclista$kilometros<- 0
recorridosCiclista$kilometros[1] <- 3.5
recorridosCiclista$kilometros[2] <- 2.6
recorridosCiclista$kilometros[3] <- 2.1
recorridosCiclista$kilometros[4] <- 2.1
recorridosCiclista$kilometros[5] <- 0.9
recorridosCiclista$kilometros[6] <- 1.5
recorridosCiclista$kilometros[7] <- 3.7
recorridosCiclista$kilometros[8] <- 2.9
recorridosCiclista$kilometros[9] <- 0.9
recorridosCiclista$kilometros[11] <- 2.1
recorridosCiclista$kilometros[12] <- 1.8
recorridosCiclista$kilometros[13] <- 0.65
recorridosCiclista$kilometros[14] <- 3.9
recorridosCiclista$kilometros[15] <- 0.9
recorridosCiclista$kilometros[16] <- 3.0
recorridosCiclista$kilometros[17] <- 1.3
recorridosCiclista$kilometros[18] <- 3.7
recorridosCiclista$kilometros[19] <- 3
recorridosCiclista$kilometros[20] <- 2.9
recorridosCiclista$kilometros[21] <- 2.8
recorridosCiclista$kilometros[22] <- 2.4
recorridosCiclista$kilometros[23] <- 1.1
recorridosCiclista$kilometros[24] <- 3.1
recorridosCiclista$kilometros[25] <- 2.9
recorridosCiclista$kilometros[26] <- 2.9
recorridosCiclista$kilometros[27] <- 2

recorridos$velocidad<- 0
for(pos in which(posUsuario)){
    if(is.na(recorridos$id_estacion_origen[pos]) | is.na(recorridos$id_estacion_destino[pos])){
        next
    }
    duracion<- as.numeric(recorridos$duracion_recorrido[pos])/3600
    posRuta<- recorridosCiclista$id_estacion_origen == recorridos$id_estacion_origen[pos] &
        recorridosCiclista$id_estacion_destino == recorridos$id_estacion_destino[pos]
    kilometros<- recorridosCiclista$kilometros[posRuta]
    recorridos$velocidad[pos]<- kilometros / duracion
}
posUsuario<- posUsuario & recorridos$velocidad > 0
mediaArmonica<- 1/mean(1/recorridos$velocidad[posUsuario])
mediaAritmetica<- mean(recorridos$velocidad[posUsuario])
```

Como es de suponer la media arm贸nica es menor a la aritm茅tica, siendo estas de `round(mediaArmonica,2)` km/h y de `r round(mediaAritmetica,2)` km/h respectivamente.

En estos casos es recomendable usar la media arm贸nica debido a que es menos sensible a los altos valores de la muestra, mientras que le da mayor importancia a los valores peque帽os, y, si se ve el histograma de las velocidades, estas suelen tener colas alargadas hacia grandes velocidades las cuales distorcionan la media aritm茅tica.

```{r,cache=TRUE,warning=FALSE}
plot_ly(recorridos[posUsuario,], x = ~velocidad,type = "histogram", histnorm = "probability", 
        name = "Distribuci贸n") %>%
    add_lines(x = rep(mediaAritmetica,2), y = c(0,0.32), name = "Media Aritm茅tica") %>%
    add_lines(x = rep(mediaArmonica,2), y = c(0,0.32), name = "Media Arm贸nica")

```


Prueba de hip贸tesis
-------------------

**Hip贸tesis nula: La proporci贸n de usuarios que tardan mas de 15 minutos en hacer el recorrido de la estacion 009 a la 066 es mayor o igual al 20%.**

**Hip贸tesis alternativa: La proporci贸n de usuarios que tardan mas de 15 minutos en hacer el recorrido de la estacion 009 a la 066 es menor al 20%.**

Al tratarse de una proporci贸n, primero creamos una columna *booleana* para indicar si la duraci贸n del recorrido fue mayor o menor a 15 minutos.
A continuaci贸n, realizamos el test de hip贸tesi (con un nivel de significaci贸n del 5%).

```{r}
df$mas_15_min <- df$duracion_recorrido_manual > 15*60

subsample <- filter(df, complete.cases(duracion_recorrido_manual))

n = nrow(filter(subsample,id_estacion_origen == 009, id_estacion_destino == 066))

phat = nrow(filter(subsample,id_estacion_origen == 009, id_estacion_destino == 066,mas_15_min == TRUE))/ n

zstat = (phat-0.2)/sqrt(0.2*(1-0.2)/n)

zcrit = qt(0.05, df = n-1)

zstat;zcrit

pvalor <- pt(zstat,df=n-1,lower.tail=TRUE);pvalor
```

Tambien puede calcularse directamente con un binom.test:

```{r}

#df$mas_15_min <- df$duracion_recorrido_manual > 15*60

binom.test( x = nrow(filter(subsample,id_estacion_origen == 009, id_estacion_destino == 066,mas_15_min == TRUE)), 
            n = nrow(filter(subsample,id_estacion_origen == 009, id_estacion_destino == 066)), 
            p = 0.2, alternative = 'less')
```

El resultado del *p-value* es mayor 0.05, con lo cual, para un nivel de confianza del 95%, no tenemos evidencia suficiente para refutar la hip贸tesis nula. En otras palabras, no puedo rechazar la posibilidad de que la proporci贸n de usuarios que tardan m谩s de 15 minutos es mayor al 20%


Evaluando la potencia del test
------------------------------

Ahora se eval煤a la *potencia* del test, osea, la probabilidad de rechazar la hip贸tesis nula, siendo esta falsa.


```{r}

pstar <- 0.19

xcrit <- qt(0.05, df = n-1)*sqrt((0.2*(1-0.2))/n)+0.2

zcrit <- (xcrit - pstar)/sqrt((pstar*(1 - pstar))/n)

beta <- 1 - pt(zcrit, df = n-1)

potencia <- 1 - beta; potencia

```

Con el resultado anterior, se obtuvo la potencia del test, ahora observamos que ocurre con la curva de potencia en la medida que variamos pstar:

````{r}



pstar <- seq(from = 0.1, to=0.2, by=0.001)

xcrit <- qt(0.05, df = n-1)*sqrt((0.2*(1-0.2))/n)+0.2

zcrit <- (xcrit - pstar)/sqrt((pstar*(1 - pstar))/n)

beta <- 1 - pt(zcrit, df = n-1)

potencia <- 1-beta

plot(pstar,potencia, ylim=c(0,1),type = "l", xlab= "mu*", ylab= "potencia", lwd=2)

```

Arriba se observa la curva de potencia para distintos valores de p estrella, se observa que para una un valor cercano al 20% como suger铆a el problema, la potencia del test es inferior al 20%. Se entiende entonces que la probabilidad de rechazar la hip贸tesis nula suponiendo que esta sea falsa es bastante baja.

A medida que suponemos que p estrella se corre hacia valores inferiores, vemos que la potencia del test sube significativamente con unos pocos corrimientos. Por lo tanto, cuanto m谩s bajo sea el p estrella, m谩s potente se vuelve el test porque la hip贸tesis nula original se volver铆a cada vez m谩s absurda.



Punto 7
-------

Para concluir si hay diferencia en el uso de la estaci贸n antes y despues de la innaguraci贸n de la estaci贸n de subte de Facultad de Derecho, se tomo la cantidad de viajes por d铆a (Se asigna un viaje al d铆a en el que este comienza), luego si encontramos una diferencia significativa en la media de viajes por d铆a (se considera un viaje de la estaci贸n si este comienza o termina en la estaci贸n).

Luego se calculan dos data frame, uno con la informaci贸n de la cantidad de viajes diarios de la estaci贸n los d铆as previos al mes de mayo, y el otro con la cantidad de viajes diarios de la estaci贸n desde mayo en adelante. 

```{r, cache=TRUE}
recorridos$facultad_derecho<- recorridos$id_estacion_destino == 1 |
    recorridos$id_estacion_origen == 1
recorridosFacultad<- recorridos %>% filter(!is.na(id_estacion_origen) & !is.na(id_estacion_destino)) %>% filter(facultad_derecho)
recorridosFacultad$mes<- as.POSIXlt(recorridosFacultad$fecha_origen_recorrido)$mon
recorridosFacultad$fecha_origen<- as.Date(recorridosFacultad$fecha_origen_recorrido)
recorridosFacultad$fecha_destino<- as.Date(recorridosFacultad$fecha_destino_recorrido)

recorridosAntes<- recorridosFacultad[recorridosFacultad$mes < 5,]
recorridosDespues<- recorridosFacultad[recorridosFacultad$mes > 4,]

viajesDiariosAntes<- recorridosAntes %>% group_by(fecha_origen) %>%
    summarise(viajes = length(fecha_origen))
viajesDiariosAntes<- as.data.frame(viajesDiariosAntes)
viajesDiariosDespues<- recorridosDespues %>% group_by(fecha_origen) %>%
    summarise(viajes = length(fecha_origen))
viajesDiariosDespues<- as.data.frame(viajesDiariosDespues)
```

La prueba de hipotesis sera:

Hip贸tesis Nula: La diferencia del promedio de viajes antes y despues de la innaguraci贸n de la estaci贸n de Subte Facultad de Derecho es igual a 0.

Hip贸tesis Alternativa: La diferencia del promedio de viajes antes y despues de la innaguraci贸n de la estaci贸n de Subte Facultad de Derecho es distinta de 0.

Esto se hara con un nivel de significaci贸n del 5%

Este test se hara con dos conjuntos de datos, uno tomando solo 4 meses de datos (Marzo y Abril en el primer set de datos, Mayo y Junio en el segundo set de datos), y otro con los 151 d铆as de datos del primer set de datos y los primeros 151 datos del segundo set de datos. En este caso la prueba no es apareada debido a que no es el mismo "sujeto" que se mide antes y despues de la innaguraci贸n.

##### Caso de 4 meses

```{r,cache=TRUE}
t.test(viajesDiariosAntes$viajes[92:151],viajesDiariosDespues$viajes[1:60],paired = FALSE,mu = 0, alternative = "two.sided")
```

Para este caso no se encuentra evidencia para rechazar la hip贸tesis nula, debido a lo alto del p-valor y ademas el 0 esta contenido dentro del intervalo de confianza.

##### Caso de 151 d铆as

```{r,cache=TRUE}
t.test(viajesDiariosAntes$viajes,viajesDiariosDespues$viajes[1:151], paired = FALSE, mu = 0,alternative = "two.sided")
```

En este caso se rechaza la hip贸tesis nula debido a que el p-valor es menor al nivel de significac铆on, por lo tanto decimos que hay evidencia estad铆stica de que la cantidad de viajes diarios es diferente, mas a煤n, dado el intervalo de confianza podemos decir que la cantidad de viajes por d铆a aumento luego de la innaguraci贸n de la estaci贸n de Subte.

Como conclusi贸n general podemos decir que si hay un cambio significativo en el uso de la estaci贸n de EcoBici antes y depues de la innaguraci贸n de la estaci贸n de Subte pero el mismo fue paulatino, ya que se requirio tomar muestras de mas d铆as para poder visualizar dicho comportamiento.

Punto 8
--------









Punto 9
-------








Boostrapping
------------

Para poder hacer este punto, se necesita conocer la edad de los usuarios, cosa que el dataset de los recorridos no tiene. Debemos primero unir la base de id de usuarios (que si tiene la informaci贸n de la edad) con la de los recorridos.

```{r}


names(users)[1] <- 'id_usuario'

# Creo un nuevo dataframe con el merge entre la informacion de las bicicletas y la de los usuarios

df_with_users <- merge(x = df, y = users,by = 'id_usuario')
df_with_users <- select(df_with_users, -c(fecha_alta,hora_alta))

# Defino funcion de correlacion

fc_cor <- function(d,i){
  d <- df_with_users[i,]
  return(cor(d$duracion_recorrido,d$usuario_edad)) # Uso duracion de recorrido y no la manual porque tiene missings
}


set.seed(123) # Me aseguro poder replicar los mismos resultados a posteriori

boot_cor <- boot(data = filter(df_with_users,id_estacion_origen == 009, id_estacion_destino == 066), statistic = fc_cor, R = 10000)
boot_cor

#histograma y qqplot
plot(boot_cor)

#intervalo de confianza:
boot.ci(boot.out = boot_cor, type = c("norm", "basic", "perc", "bca"))

```